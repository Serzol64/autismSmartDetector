{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1024609,"sourceType":"datasetVersion","datasetId":564001}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split, DataLoader\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport requests\nimport glob\nfrom io import BytesIO\n\n# Задание базовых параметров\nbatch_size = 32\nlearning_rate = 0.001\nepochs = 10\n\n# Трансформация изображений\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),           # Приведение к одному размеру\n    transforms.RandomHorizontalFlip(),        # Горизонтальное отражение (для увеличения разнообразия)\n    transforms.ToTensor(),                    # Преобразование в Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Нормализация\n])\n\n# Загрузка объединённых данных из папки \"consolidated\"\nfull_dataset = datasets.ImageFolder(root='/kaggle/input/autism-image-data/AutismDataset/consolidated', transform=transform)\n\n# Разбиение данных на train, valid и test\ntrain_size = int(len(full_dataset) * 0.7)\nvalid_size = int(len(full_dataset) * 0.15)\ntest_size = len(full_dataset) - train_size - valid_size\n\ntrain_dataset, valid_dataset, test_dataset = random_split(full_dataset, [train_size, valid_size, test_size])\n\n# Создание загрузчиков данных\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:25:56.322886Z","iopub.execute_input":"2025-08-05T05:25:56.323121Z","iopub.status.idle":"2025-08-05T05:26:00.923256Z","shell.execute_reply.started":"2025-08-05T05:25:56.323099Z","shell.execute_reply":"2025-08-05T05:26:00.922660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Архитектура модели\nclass AutismClassifier(nn.Module):\n    def __init__(self):\n        super(AutismClassifier, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten()\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64*56*56, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 2)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.fc_layers(x)\n        return x\n\n# Перемещаем модель на устройство (GPU или CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutismClassifier().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Обучение модели\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n        running_loss += loss.item()\n    accuracy_train = 100 * correct_train / total_train\n    print(f\"[Эпоха {epoch+1}/{epochs}] Loss: {running_loss:.3f}, Train Accuracy: {accuracy_train:.2f}%\")\n\n    # Проверка на валидационном наборе\n    model.eval()\n    correct_valid = 0\n    total_valid = 0\n    with torch.no_grad():\n        for images, labels in valid_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total_valid += labels.size(0)\n            correct_valid += (predicted == labels).sum().item()\n    accuracy_valid = 100 * correct_valid / total_valid\n    print(f\"[Эпоха {epoch+1}/{epochs}] Validation Accuracy: {accuracy_valid:.2f}%\")\n\ntorch.save(model.state_dict(), 'best_model.pth')\nprint(\"Модель успешно сохранена!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:26:00.924717Z","iopub.execute_input":"2025-08-05T05:26:00.925061Z","iopub.status.idle":"2025-08-05T05:28:09.931876Z","shell.execute_reply.started":"2025-08-05T05:26:00.925043Z","shell.execute_reply":"2025-08-05T05:28:09.931125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Загрузка модели из pth-файла\nloaded_model = AutismClassifier().to(device)\nloaded_model.load_state_dict(torch.load('best_model.pth'))\nloaded_model.eval()\n\ncorrect_test = 0\ntotal_test = 0\npredictions = []\nground_truth = []\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = loaded_model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\n        ground_truth.extend(labels.cpu().numpy())\n        total_test += labels.size(0)\n        correct_test += (predicted == labels).sum().item()\n\naccuracy_test = 100 * correct_test / total_test\nprint(f\"\\nФинальная точность на тестовом наборе: {accuracy_test:.2f}%\\n\")\n\n# Показываем подробный классификационный отчёт\nreport = classification_report(np.array(ground_truth), np.array(predictions), digits=4)\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:28:09.932666Z","iopub.execute_input":"2025-08-05T05:28:09.932895Z","iopub.status.idle":"2025-08-05T05:28:12.314525Z","shell.execute_reply.started":"2025-08-05T05:28:09.932878Z","shell.execute_reply":"2025-08-05T05:28:12.313846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Определение аутичных черт по одному фото из локальной ФС","metadata":{}},{"cell_type":"code","source":"# Переносим модель на нужное устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutismClassifier().to(device)\nmodel.load_state_dict(torch.load('best_model.pth', map_location=device))\nmodel.eval()\n\n# Загружаем и предобрабатываем изображение\nimage_path = \"/kaggle/input/autism-image-data/AutismDataset/consolidated/Autistic/0015.jpg\"\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nimage = Image.open(image_path)\nimage_tensor = transform(image).unsqueeze_(0).to(device)  # Преобразовываем в Tensor и добавляем размер батча\n\n# Прогон через модель\nwith torch.no_grad():\n    output = model(image_tensor)\n    probabilities = torch.softmax(output, dim=1)\n    pred_class = torch.argmax(probabilities, dim=1)\n\n# Интерпретация результата\nclasses = [\"Non-Autistic\", \"Autistic\"]  # Названия классов зависят от вашей задачи\nprint(f\"Прогноз для изображения '{image_path}' — {classes[pred_class.item()]}. Вероятности: {probabilities.tolist()[0]} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:28:12.315308Z","iopub.execute_input":"2025-08-05T05:28:12.315505Z","iopub.status.idle":"2025-08-05T05:28:12.694644Z","shell.execute_reply.started":"2025-08-05T05:28:12.315489Z","shell.execute_reply":"2025-08-05T05:28:12.693834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Определение аутичных черт по одному фото из URL","metadata":{}},{"cell_type":"code","source":"url = \"https://i.pinimg.com/originals/55/b7/93/55b793764f01746f78f54820caa9caeb.jpg\"\nresponse = requests.get(url)\nimage_bytes = response.content\n\n# Преобразуем байты в изображение и далее по схеме\nimage = Image.open(BytesIO(image_bytes))\nimage_tensor = transform(image).unsqueeze_(0).to(device)\n\n# Прогон через модель\nwith torch.no_grad():\n    output = model(image_tensor)\n    probabilities = torch.softmax(output, dim=1)\n    pred_class = torch.argmax(probabilities, dim=1)\n\n# Результат\nprint(f\"Прогноз для изображения по URL '{url}' — {classes[pred_class.item()]}. Вероятности: {probabilities.tolist()[0]} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:28:12.695486Z","iopub.execute_input":"2025-08-05T05:28:12.695771Z","iopub.status.idle":"2025-08-05T05:28:12.747906Z","shell.execute_reply.started":"2025-08-05T05:28:12.695751Z","shell.execute_reply":"2025-08-05T05:28:12.747146Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Определение аутичных черт по множеству фото из локальной ФС","metadata":{}},{"cell_type":"code","source":"# Список путей к изображениям\nimages_paths = glob.glob(\"/kaggle/input/autism-image-data/AutismDataset/valid/Autistic/*.jpg\")\n\n# Преобразование данных\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Пользовательская функция для открытия и преобразования изображений\ndef load_and_transform(path):\n    image = Image.open(path)\n    return transform(image)\n\n# Создаем генератор изображений\nimage_tensors = [load_and_transform(path) for path in images_paths]\n\n# Пакуем в батч\nimage_batch = torch.stack(image_tensors).to(device)\n\n# Прогон через модель\nwith torch.no_grad():\n    outputs = model(image_batch)\n    probabilities = torch.softmax(outputs, dim=1)\n    preds = torch.argmax(probabilities, dim=1)\n\n# Выводим прогнозы\nfor i, path in enumerate(images_paths):\n    print(f\"Изображение {path}: {classes[preds[i].item()]}, Вероятности: {probabilities[i].tolist()} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T05:36:17.883813Z","iopub.execute_input":"2025-08-05T05:36:17.884122Z","iopub.status.idle":"2025-08-05T05:36:18.141175Z","shell.execute_reply.started":"2025-08-05T05:36:17.884100Z","shell.execute_reply":"2025-08-05T05:36:18.140368Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ","metadata":{}}]}